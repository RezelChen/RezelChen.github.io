<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 4.2.1">
  <link rel="apple-touch-icon" sizes="180x180" href="/blog/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/blog/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/blog/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/blog/images/logo.svg" color="#222">

<link rel="stylesheet" href="/blog/css/main.css">


<link rel="stylesheet" href="/blog/lib/font-awesome/css/all.min.css">
  
  <link rel="stylesheet" href="/blog/lib/animate-css/animate.min.css">

<script class="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"rezelchen.github.io","root":"/blog/","scheme":"Muse","version":"8.0.0-rc.4","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":false,"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}},"localsearch":{"enable":false,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}}};
  </script>

  <meta property="og:type" content="website">
<meta property="og:title" content="Ray Chen&#39;s Blog">
<meta property="og:url" content="https://rezelchen.github.io/index.html">
<meta property="og:site_name" content="Ray Chen&#39;s Blog">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="Ray Chen">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="https://rezelchen.github.io/">


<script class="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : true,
    isPost : false,
    lang   : 'en'
  };
</script>

  <title>Ray Chen's Blog</title>
  






  <noscript>
  <style>
  body { margin-top: 2rem; }

  .use-motion .menu-item,
  .use-motion .sidebar,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header {
    visibility: visible;
  }

  .use-motion .header,
  .use-motion .site-brand-container .toggle,
  .use-motion .footer { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle,
  .use-motion .custom-logo-image {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line {
    transform: scaleX(1);
  }

  .search-pop-overlay, .sidebar-nav { display: none; }
  .sidebar-panel { display: block; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <main class="main">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader">
        <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar">
    </div>
  </div>

  <div class="site-meta">

    <a href="/blog/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">Ray Chen's Blog</h1>
      <i class="logo-line"></i>
    </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
    </div>
  </div>
</div>







</div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <!--noindex-->
      <section class="post-toc-wrap sidebar-panel">
      </section>
      <!--/noindex-->

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">Ray Chen</p>
  <div class="site-description" itemprop="description"></div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/blog/archives">
          <span class="site-state-item-count">7</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">1</span>
        <span class="site-state-item-name">tags</span>
      </div>
  </nav>
</div>



      </section>
    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </header>

      
  <div class="back-to-top">
    <i class="fa fa-arrow-up"></i>
    <span>0%</span>
  </div>

<noscript>
  <div id="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


      <div class="main-inner">
        

        <div class="content index posts-expand">
          
      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://rezelchen.github.io/2020/08/13/DDIA7/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="Ray Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ray Chen's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/2020/08/13/DDIA7/" class="post-title-link" itemprop="url">Note for DDIA in Chapter 7</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>
              

              <time title="Created: 2020-08-13 08:37:00 / Modified: 11:53:41" itemprop="dateCreated datePublished" datetime="2020-08-13T08:37:00+00:00">2020-08-13</time>
            </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Transactions"><a href="#Transactions" class="headerlink" title="Transactions"></a>Transactions</h2><p>A transaction is a way for an application to group several reads and writes together into a logical unit. Conceptually, all the reads and writes in a transaction are executed as one operation: either the entire transaction succeeds (<em>commit</em>) or it fails (<em>abort, rollback</em>). </p>
<p>In this chapter, we will examine many examples of things that can go wrong, and explore the algorithms that databases use to guard against those issues. We will go especially deep in the area of concurrency control, discussing various kinds of race conditions that can occur and how databases implement isolation levels such as <em>read committed</em>, <em>snapshot isolation</em>, and <em>serializability</em>.</p>
<h3 id="The-Slippery-Concept-of-a-Transaction"><a href="#The-Slippery-Concept-of-a-Transaction" class="headerlink" title="The Slippery Concept of a Transaction"></a>The Slippery Concept of a Transaction</h3><h4 id="The-Meaning-of-ACID"><a href="#The-Meaning-of-ACID" class="headerlink" title="The Meaning of ACID"></a>The Meaning of ACID</h4><h5 id="Atomicity"><a href="#Atomicity" class="headerlink" title="Atomicity"></a>Atomicity</h5><p>If the writes are grouped together into an atomic transaction, and the transaction cannot be completed (committed) due to a fault, then the transaction is aborted and the database must discard or undo any writes it has made so far in that transaction.</p>
<h5 id="Consistency"><a href="#Consistency" class="headerlink" title="Consistency"></a>Consistency</h5><p>The idea of ACID consistency is that you have certain statements about your data (invariants) that must always be true.</p>
<p>However, this idea of consistency depends on the application’s notion of invariants, and it’s the application’s responsibility to define its transactions correctly so that they preserve consistency. </p>
<p>The application may rely on the database’s atomicity and isolation properties in order to achieve consistency, but it’s not up to the database alone. </p>
<h5 id="Isolation"><a href="#Isolation" class="headerlink" title="Isolation"></a>Isolation</h5><p><em>Isolation</em> in the sense of ACID means that concurrently executing transactions are isolated from each other: they cannot step on each other’s toes. The classic database textbooks formalize isolation as <em>serializability</em>, which means that each transaction can pretend that it is the only transaction running on the entire database.</p>
<p>However, in practice, serializable isolation is rarely used, because it carries a performance penalty. </p>
<h5 id="Durability"><a href="#Durability" class="headerlink" title="Durability"></a>Durability</h5><p><em>Durability</em> is the promise that once a transaction has com‐ mitted successfully, any data it has written will not be forgotten, even if there is a hardware fault or the database crashes.</p>
<p>In a replicated database, durabil‐ ity may mean that the data has been successfully copied to some number of nodes. In order to provide a durability guarantee, a database must wait until these writes or replications are complete before reporting a transaction as successfully committed.</p>
<h4 id="Single-Object-and-Multi-Object-Operations"><a href="#Single-Object-and-Multi-Object-Operations" class="headerlink" title="Single-Object and Multi-Object Operations"></a>Single-Object and Multi-Object Operations</h4><h5 id="Single-object-writes"><a href="#Single-object-writes" class="headerlink" title="Single-object writes"></a>Single-object writes</h5><p>Storage engines almost universally aim to provide atomicity and isolation on the level of a single object (such as a key- value pair) on one node. Atomicity can be implemented using a log for crash recovery, and isolation can be implemented using a lock on each object (allowing only one thread to access an object at any one time).</p>
<p>Some databases also provide more complex atomic operations,iv such as an increment operation and compare-and-set operation.</p>
<h5 id="The-need-for-multi-object-transactions"><a href="#The-need-for-multi-object-transactions" class="headerlink" title="The need for multi-object transactions"></a>The need for multi-object transactions</h5><h5 id="Handling-errors-and-aborts"><a href="#Handling-errors-and-aborts" class="headerlink" title="Handling errors and aborts"></a>Handling errors and aborts</h5><p>A key feature of a transaction is that it can be aborted and safely retried if an error occurred. </p>
<p>Although retrying an aborted transaction is a simple and effective error handling mechanism, it isn’t perfect:</p>
<ul>
<li><p>If the transaction actually succeeded, but the network failed while the server tried to acknowledge the successful commit to the client (so the client thinks it failed), then retrying the transaction causes it to be performed twice—unless you have an additional application-level deduplication mechanism in place.</p>
</li>
<li><p>If the error is due to overload, retrying the transaction will make the problem worse, not better. To avoid such feedback cycles, you can limit the number of retries, use exponential backoff, and handle overload-related errors differently from other errors (if possible).</p>
</li>
<li><p>It is only worth retrying after transient errors (for example due to deadlock, iso‐ lation violation, temporary network interruptions, and failover); after a perma‐ nent error (e.g., constraint violation) a retry would be pointless.</p>
</li>
<li><p>If the transaction also has side effects outside of the database, those side effects may happen even if the transaction is aborted. For example, if you’re sending an email, you wouldn’t want to send the email again every time you retry the trans‐ action. If you want to make sure that several different systems either commit or abort together, two-phase commit can help.</p>
</li>
<li><p>If the client process fails while retrying, any data it was trying to write to the database is lost.</p>
</li>
</ul>
<h3 id="Weak-Isolation-Levels"><a href="#Weak-Isolation-Levels" class="headerlink" title="Weak Isolation Levels"></a>Weak Isolation Levels</h3><h4 id="Read-Committed"><a href="#Read-Committed" class="headerlink" title="Read Committed"></a>Read Committed</h4><p>The most basic level of transaction isolation is read committed.v It makes two guarantees:</p>
<ol>
<li><p>When reading from the database, you will only see data that has been committed (no dirty reads).</p>
</li>
<li><p>When writing to the database, you will only overwrite data that has been committed (no dirty writes).</p>
</li>
</ol>
<h5 id="No-dirty-reads"><a href="#No-dirty-reads" class="headerlink" title="No dirty reads"></a>No dirty reads</h5><p>There are a few reasons why it’s useful to prevent dirty reads:</p>
<ul>
<li><p>If a transaction needs to update several objects, a dirty read means that another transaction may see some of the updates but not others.</p>
</li>
<li><p>If a transaction aborts, any writes it has made need to be rolled back. If the database allows dirty reads, that means a transaction may see data that is later rolled back.</p>
</li>
</ul>
<h5 id="No-dirty-writes"><a href="#No-dirty-writes" class="headerlink" title="No dirty writes"></a>No dirty writes</h5><p>Transactions running at the read committed isolation level must prevent dirty writes, usually by delaying the second write until the first write’s transaction has committed or aborted.</p>
<p>By preventing dirty writes, this isolation level avoids some kinds of concurrency problems:</p>
<ul>
<li><p>If transactions update multiple objects, dirty writes can lead to a bad outcome.</p>
</li>
<li><p>However, read committed does not prevent the race condition between two counter increments in Figure 7-1.</p>
</li>
</ul>
<h5 id="Implementing-read-committed"><a href="#Implementing-read-committed" class="headerlink" title="Implementing read committed"></a>Implementing read committed</h5><p>Most commonly, databases prevent dirty writes by using row-level locks: when a transaction wants to modify a particular object (row or document), it must first acquire a lock on that object. It must then hold that lock until the transaction is committed or aborted.</p>
<p>How do we prevent dirty reads? One option would be to use the same lock, and to require any transaction that wants to read an object to briefly acquire the lock and then release it again immediately after reading.</p>
<p>However, the approach of requiring read locks does not work well in practice, because one long-running write transaction can force many read-only transactions to wait until the long-running transaction has completed.</p>
<p>The database remembers both the old committed value and the new value set by the transaction that currently holds the write lock. While the transaction is ongoing, any other transactions that read the object are simply given the old value. Only when the new value is committed do transactions switch over to reading the new value.</p>
<h4 id="Snapshot-Isolation-and-Repeatable-Read"><a href="#Snapshot-Isolation-and-Repeatable-Read" class="headerlink" title="Snapshot Isolation and Repeatable Read"></a>Snapshot Isolation and Repeatable Read</h4><p><em>nonrepeatable read</em> or <em>read skew</em></p>
<p>Some situations cannot tolerate such temporary inconsistency:</p>
<ul>
<li>Backups</li>
<li>Analytic queries and integrity checks</li>
</ul>
<p><em>Snapshot isolation</em> is the most common solution to this problem. The idea is that each transaction reads from a consistent snapshot of the database—that is, the trans‐ action sees all the data that was committed in the database at the start of the transac‐ tion. Even if the data is subsequently changed by another transaction, each transaction sees only the old data from that particular point in time.</p>
<p>Snapshot isolation is a boon for long-running, read-only queries such as backups and analytics.</p>
<h5 id="Implementing-snapshot-isolation"><a href="#Implementing-snapshot-isolation" class="headerlink" title="Implementing snapshot isolation"></a>Implementing snapshot isolation</h5><p>Like read committed isolation, implementations of snapshot isolation typically use write locks to prevent dirty writes. However, reads do not require any locks. From a performance point of view, a key principle of snapshot isolation is <em>readers never block writers, and writers never block readers</em>. This allows a database to handle long-running read queries on a consistent snapshot at the same time as processing writes normally, without any lock contention between the two.</p>
<p>The database must potentially keep several different committed versions of an object, because various in-progress trans‐ actions may need to see the state of the database at different points in time. Because it maintains several versions of an object side by side, this technique is known as <em>multi- version concurrency control</em> (MVCC).</p>
<p>An update is internally translated into a delete and a create. </p>
<h5 id="Visibility-rules-for-observing-a-consistent-snapshot"><a href="#Visibility-rules-for-observing-a-consistent-snapshot" class="headerlink" title="Visibility rules for observing a consistent snapshot"></a>Visibility rules for observing a consistent snapshot</h5><p>When a transaction reads from the database, transaction IDs are used to decide which objects it can see and which are invisible. By carefully defining visibility rules, the database can present a consistent snapshot of the database to the application. This works as follows:</p>
<ol>
<li><p>At the start of each transaction, the database makes a list of all the other transactions that are in progress (not yet committed or aborted) at that time. Any writes that those transactions have made are ignored, even if the transactions subsequently commit.</p>
</li>
<li><p>Any writes made by aborted transactions are ignored.</p>
</li>
<li><p>Any writes made by transactions with a later transaction ID (i.e., which started after the current transaction started) are ignored, regardless of whether those transactions have committed.</p>
</li>
<li><p>All other writes are visible to the application’s queries.</p>
</li>
</ol>
<p>Put another way, an object is visible if both of the following conditions are true:</p>
<ul>
<li><p>At the time when the reader’s transaction started, the transaction that created the object had already committed.</p>
</li>
<li><p>The object is not marked for deletion, or if it is, the transaction that requested deletion had not yet committed at the time when the reader’s transaction started.</p>
</li>
</ul>
<h5 id="Indexes-and-snapshot-isolation"><a href="#Indexes-and-snapshot-isolation" class="headerlink" title="Indexes and snapshot isolation"></a>Indexes and snapshot isolation</h5><p>…</p>
<h5 id="Repeatable-read-and-naming-confusion"><a href="#Repeatable-read-and-naming-confusion" class="headerlink" title="Repeatable read and naming confusion"></a>Repeatable read and naming confusion</h5><h4 id="Preventing-Lost-Updates"><a href="#Preventing-Lost-Updates" class="headerlink" title="Preventing Lost Updates"></a>Preventing Lost Updates</h4><p>The <em>lost update</em> problem can occur if an application reads some value from the data‐ base, modifies it, and writes back the modified value (a read-modify-write cycle). If two transactions do this concurrently, one of the modifications can be lost, because the second write does not include the first modification. (We sometimes say that the later write <em>clobbers</em> the earlier write.) This pattern occurs in various different scenarios:</p>
<ul>
<li><p>Incrementing a counter or updating an account balance (requires reading the current value, calculating the new value, and writing back the updated value)</p>
</li>
<li><p>Making a local change to a complex value, e.g., adding an element to a list within a JSON document (requires parsing the document, making the change, and writ‐ ing back the modified document)</p>
</li>
<li><p>Two users editing a wiki page at the same time, where each user saves their changes by sending the entire page contents to the server, overwriting whatever is currently in the database</p>
</li>
</ul>
<h5 id="Atomic-write-operations"><a href="#Atomic-write-operations" class="headerlink" title="Atomic write operations"></a>Atomic write operations</h5><p>Many databases provide atomic update operations, which remove the need to implement read-modify-write cycles in application code. They are usually the best solution if your code can be expressed in terms of those operations. </p>
<p>Atomic operations are usually implemented by taking an exclusive lock on the object when it is read so that no other transaction can read it until the update has been applied. This technique is sometimes known as cursor stability. Another option is to simply force all atomic operations to be executed on a single thread.</p>
<h5 id="Explicit-locking"><a href="#Explicit-locking" class="headerlink" title="Explicit locking"></a>Explicit locking</h5><p>Another option for preventing lost updates, if the database’s built-in atomic opera‐ tions don’t provide the necessary functionality, is for the application to explicitly lock objects that are going to be updated. Then the application can perform a read- modify-write cycle, and if any other transaction tries to concurrently read the same object, it is forced to wait until the first read-modify-write cycle has completed.</p>
<h5 id="Automatically-detecting-lost-updates"><a href="#Automatically-detecting-lost-updates" class="headerlink" title="Automatically detecting lost updates"></a>Automatically detecting lost updates</h5><p>An alternative is to allow them to execute in parallel and, if the transaction manager detects a lost update, abort the transaction and force it to retry its read-modify-write cycle.</p>
<p>An advantage of this approach is that databases can perform this check efficiently in conjunction with snapshot isolation.</p>
<h5 id="Compare-and-set"><a href="#Compare-and-set" class="headerlink" title="Compare-and-set"></a>Compare-and-set</h5><p>The purpose of this operation is to avoid lost updates by allowing an update to happen only if the value has not changed since you last read it. If the current value does not match what you previously read, the update has no effect, and the read-modify-write cycle must be retried.</p>
<p>Check whether your database’s compare-and-set operation is safe before relying on it.</p>
<h5 id="Conflict-resolution-and-replication"><a href="#Conflict-resolution-and-replication" class="headerlink" title="Conflict resolution and replication"></a>Conflict resolution and replication</h5><p>Locks and compare-and-set operations assume that there is a single up-to-date copy of the data. However, they do not apply in the context that databases with multi-leader or leaderless replication.</p>
<p>Atomic operations can work well in a replicated context.</p>
<p>On the other hand, the last write wins (LWW) conflict resolution method is prone to lost updates.</p>
<h4 id="Write-Skew-and-Phantoms"><a href="#Write-Skew-and-Phantoms" class="headerlink" title="Write Skew and Phantoms"></a>Write Skew and Phantoms</h4><h5 id="Characterizing-write-skew"><a href="#Characterizing-write-skew" class="headerlink" title="Characterizing write skew"></a>Characterizing write skew</h5><p><em>Write skew</em> is neither a dirty write nor a lost update, because the two transactions are updating two different objects.</p>
<p>You can think of write skew as a generalization of the lost update problem. Write skew can occur if two transactions read the same objects, and then update some of those objects (different transactions may update different objects). In the special case where different transactions update the same object, you get a dirty write or lost update anomaly (depending on the timing).</p>
<p>If you can’t use a serializable isolation level, the second-best option in this case is probably to explicitly lock the rows that the transaction depends on. </p>
<h5 id="More-examples-of-write-skew"><a href="#More-examples-of-write-skew" class="headerlink" title="More examples of write skew"></a>More examples of write skew</h5><h5 id="Phantoms-causing-write-skew"><a href="#Phantoms-causing-write-skew" class="headerlink" title="Phantoms causing write skew"></a>Phantoms causing write skew</h5><p>All of these examples follow a similar pattern:</p>
<ol>
<li><p>A SELECT query checks whether some requirement is satisfied by searching for rows that match some search condition (there are at least two doctors on call, there are no existing bookings for that room at that time, the position on the board doesn’t already have another figure on it, the username isn’t already taken, there is still money in the account).</p>
</li>
<li><p>Depending on the result of the first query, the application code decides how to continue (perhaps to go ahead with the operation, or perhaps to report an error to the user and abort).</p>
</li>
<li><p>If the application decides to go ahead, it makes a write (INSERT, UPDATE, or DELETE) to the database and commits the transaction.</p>
</li>
<li><p>The effect of this write changes the precondition of the decision of step 2. In other words, if you were to repeat the SELECT query from step 1 after commiting the write, you would get a different result, because the write changed the set of rows matching the search condition (there is now one fewer doctor on call, the meeting room is now booked for that time, the position on the board is now taken by the figure that was moved, the username is now taken, there is now less money in the account).</p>
</li>
</ol>
<p>This effect, where a write in one transaction changes the result of a search query in another transaction, is called a <em>phantom</em>. Snapshot isolation avoids phantoms in read-only queries, but in read-write transactions like the examples we discussed, phantoms can lead to particularly tricky cases of write skew.</p>
<h5 id="Materializing-conflicts"><a href="#Materializing-conflicts" class="headerlink" title="Materializing conflicts"></a>Materializing conflicts</h5><p>If the problem of phantoms is that there is no object to which we can attach the locks, perhaps we can artificially introduce a lock object into the database?</p>
<p>This approach is called <em>materializing conflicts</em>, because it takes a phantom and turns it into a lock conflict on a concrete set of rows that exist in the database.</p>
<h3 id="Serializability"><a href="#Serializability" class="headerlink" title="Serializability"></a>Serializability</h3><p>Most databases that provide serializability today use one of three techniques, which we will explore in the rest of this chapter:</p>
<ul>
<li><p>Literally executing transactions in a serial order</p>
</li>
<li><p>Two-phase locking, which for several decades was the only viable option</p>
</li>
<li><p>Optimistic concurrency control techniques such as serializable snapshot isolation</p>
</li>
</ul>
<h4 id="Actual-Serial-Execution"><a href="#Actual-Serial-Execution" class="headerlink" title="Actual Serial Execution"></a>Actual Serial Execution</h4><p>Two developments caused this rethink:</p>
<ul>
<li><p>RAM became cheap enough that for many use cases is now feasible to keep the entire active dataset in memory.</p>
</li>
<li><p>Database designers realized that OLTP transactions are usually short and only make a small number of reads and writes. By contrast, long-running analytic queries are typically read- only, so they can be run on a consistent snapshot (using snapshot isolation) outside of the serial execution loop.</p>
</li>
</ul>
<p>In order to make the most of that single thread, transac‐ tions need to be structured differently from their traditional form.</p>
<h5 id="Encapsulating-transactions-in-stored-procedures"><a href="#Encapsulating-transactions-in-stored-procedures" class="headerlink" title="Encapsulating transactions in stored procedures"></a>Encapsulating transactions in stored procedures</h5><p>The application must submit the entire transaction code to the database ahead of time, as a <em>stored procedure</em>. </p>
<h5 id="Pros-and-cons-of-stored-procedures"><a href="#Pros-and-cons-of-stored-procedures" class="headerlink" title="Pros and cons of stored procedures"></a>Pros and cons of stored procedures</h5><p>Stored procedures have gained a somewhat bad reputation, for various reasons:</p>
<ul>
<li><p>Each database vendor has its own language for stored procedures. These languages haven’t kept up with developments in general-purpose programming languages, so they look quite ugly and archaic from today’s point of view, and they lack the ecosystem of libraries that you find with most programming languages.</p>
</li>
<li><p>Code running in a database is difficult to manage: compared to an application server, it’s harder to debug, more awkward to keep in version control and deploy, trickier to test, and difficult to integrate with a metrics collection system for monitoring.</p>
</li>
<li><p>A database is often much more performance-sensitive than an application server. A badly written stored procedure in a database can cause much more trouble than equivalent badly written code in an application server.</p>
</li>
</ul>
<p>With stored procedures and in-memory data, executing all transactions on a single thread becomes feasible. </p>
<h5 id="Partitioning"><a href="#Partitioning" class="headerlink" title="Partitioning"></a>Partitioning</h5><p>If you can find a way of partitioning your dataset so that each transaction only needs to read and write data within a single partition, then each partition can have its own transaction processing thread running independently from the others. </p>
<p>However, for any transaction that needs to access multiple partitions, the database must coordinate the transaction across all the partitions that it touches. The stored procedure needs to be performed in lock-step across all partitions to ensure serializa‐ bility across the whole system.</p>
<h5 id="Summary-of-serial-execution"><a href="#Summary-of-serial-execution" class="headerlink" title="Summary of serial execution"></a>Summary of serial execution</h5><p>Serial execution of transactions has become a viable way of achieving serializable iso‐ lation within certain constraints:</p>
<ul>
<li><p>Every transaction must be small and fast, because it takes only one slow transac‐ tion to stall all transaction processing.</p>
</li>
<li><p>It is limited to use cases where the active dataset can fit in memory. Rarely accessed data could potentially be moved to disk, but if it needed to be accessed in a single-threaded transaction, the system would get very slow.x</p>
</li>
<li><p>Write throughput must be low enough to be handled on a single CPU core, or else transactions need to be partitioned without requiring cross-partition coordination.</p>
</li>
<li><p>Cross-partition transactions are possible, but there is a hard limit to the extent to which they can be used.</p>
</li>
</ul>
<h4 id="Two-Phase-Locking-2PL"><a href="#Two-Phase-Locking-2PL" class="headerlink" title="Two-Phase Locking (2PL)"></a>Two-Phase Locking (2PL)</h4><p>Sev‐ eral transactions are allowed to concurrently read the same object as long as nobody is writing to it. But as soon as anyone wants to write (modify or delete) an object, exclusive access is required:</p>
<ul>
<li><p>If transaction A has read an object and transaction B wants to write to that object, B must wait until A commits or aborts before it can continue. (This ensures that B can’t change the object unexpectedly behind A’s back.)</p>
</li>
<li><p>If transaction A has written an object and transaction B wants to read that object, B must wait until A commits or aborts before it can continue. </p>
</li>
</ul>
<p>In 2PL, writers don’t just block other writers; they also block readers and vice versa.</p>
<h5 id="Implementation-of-two-phase-locking"><a href="#Implementation-of-two-phase-locking" class="headerlink" title="Implementation of two-phase locking"></a>Implementation of two-phase locking</h5><p>The blocking of readers and writers is implemented by a having a lock on each object in the database. The lock can either be in <em>shared mode</em> or in <em>exclusive mode</em>. The lock is used as follows:</p>
<ul>
<li><p>If a transaction wants to read an object, it must first acquire the lock in shared mode. Several transactions are allowed to hold the lock in shared mode simulta‐ neously, but if another transaction already has an exclusive lock on the object, these transactions must wait.</p>
</li>
<li><p>If a transaction wants to write to an object, it must first acquire the lock in exclusive mode. </p>
</li>
<li><p>If a transaction first reads and then writes an object, it may upgrade its shared lock to an exclusive lock. The upgrade works the same as getting an exclusive lock directly.</p>
</li>
<li><p>After a transaction has acquired the lock, it must continue to hold the lock until the end of the transaction (commit or abort). This is where the name “two-phase” comes from: the first phase (while the transaction is executing) is when the locks are acquired, and the second phase (at the end of the transaction) is when all the locks are released.</p>
</li>
</ul>
<p>Since so many locks are in use, it can happen quite easily that transaction A is stuck waiting for transaction B to release its lock, and vice versa. This situation is called deadlock. The database automatically detects deadlocks between transactions and aborts one of them so that the others can make progress. The aborted transaction needs to be retried by the application.</p>
<h5 id="Performance-of-two-phase-locking"><a href="#Performance-of-two-phase-locking" class="headerlink" title="Performance of two-phase locking"></a>Performance of two-phase locking</h5><p>Although deadlocks can happen with the lock-based read committed isolation level, they occur much more frequently under 2PL serializable isolation (depending on the access patterns of your transaction). This can be an additional performance problem: when a transaction is aborted due to deadlock and is retried, it needs to do its work all over again. If deadlocks are frequent, this can mean significant wasted effort.</p>
<h5 id="Predicate-locks"><a href="#Predicate-locks" class="headerlink" title="Predicate locks"></a>Predicate locks</h5><p>A database with serializable isolation must prevent phantoms.</p>
<p>How do we implement this? Conceptually, we need a <em>predicate lock</em>. It works similarly to the shared/exclusive lock described earlier, but rather than belonging to a particular object (e.g., one row in a table), it belongs to all objects that match some search condition.</p>
<p>A predicate lock restricts access as follows:</p>
<ul>
<li><p>If transaction A wants to read objects matching some condition, like in that SELECT query, it must acquire a shared-mode predicate lock on the conditions of the query. If another transaction B currently has an exclusive lock on any object matching those conditions, A must wait until B releases its lock before it is allowed to make its query.</p>
</li>
<li><p>If transaction A wants to insert, update, or delete any object, it must first check whether either the old or the new value matches any existing predicate lock. If there is a matching predicate lock held by transaction B, then A must wait until B has committed or aborted before it can continue.</p>
</li>
</ul>
<p>The key idea here is that a predicate lock applies even to objects that do not yet exist in the database, but which might be added in the future (phantoms). If two-phase locking includes predicate locks, the database prevents all forms of write skew and other race conditions, and so its isolation becomes serializable.</p>
<h5 id="Index-range-locks"><a href="#Index-range-locks" class="headerlink" title="Index-range locks"></a>Index-range locks</h5><p>Most databases with 2PL actually implement <em>index-range locking</em> (also known as <em>next-key locking</em>), which is a simplified approximation of predicate locking.</p>
<p>Index-range locks are not as precise as predicate locks would be (they may lock a bigger range of objects than is strictly necessary to maintain serializability), but since they have much lower overheads, they are a good compromise.</p>
<p>If there is no suitable index where a range lock can be attached, the database can fall back to a shared lock on the entire table.</p>
<h4 id="Serializable-Snapshot-Isolation-SSI"><a href="#Serializable-Snapshot-Isolation-SSI" class="headerlink" title="Serializable Snapshot Isolation (SSI)"></a>Serializable Snapshot Isolation (SSI)</h4><h5 id="Pessimistic-versus-optimistic-concurrency-control"><a href="#Pessimistic-versus-optimistic-concurrency-control" class="headerlink" title="Pessimistic versus optimistic concurrency control"></a>Pessimistic versus optimistic concurrency control</h5><p>Two-phase locking is a so-called <em>pessimistic</em> concurrency control mechanism.</p>
<p>By contrast, serializable snapshot isolation is an <em>optimistic</em> concurrency control technique. Optimistic in this context means that instead of blocking if something potentially dangerous happens, transactions continue anyway, in the hope that everything will turn out all right. When a transaction wants to commit, the database checks whether anything bad happened (i.e., whether isolation was violated); if so, the transaction is aborted and has to be retried. Only transactions that executed serializably are allowed to commit.</p>
<p>On top of snapshot isolation, SSI adds an algorithm for detecting serialization conflicts among writes and determining which transactions to abort.</p>
<h5 id="Decisions-based-on-an-outdated-premise"><a href="#Decisions-based-on-an-outdated-premise" class="headerlink" title="Decisions based on an outdated premise"></a>Decisions based on an outdated premise</h5><p>To be safe, the database needs to assume that any change in the query result (the premise) means that writes in that transaction may be invalid.  In order to provide serializable isolation, the database must detect situations in which a transaction may have acted on an outdated premise and abort the transaction in that case.</p>
<p>How does the database know if a query result might have changed? There are two cases to consider:</p>
<ul>
<li><p>Detecting reads of a stale MVCC object version (uncommitted write occurred before the read)</p>
</li>
<li><p>Detecting writes that affect prior reads (the write occurs after the read)</p>
</li>
</ul>
<h5 id="Detecting-stale-MVCC-reads"><a href="#Detecting-stale-MVCC-reads" class="headerlink" title="Detecting stale MVCC reads"></a>Detecting stale MVCC reads</h5><p>When the transac‐ tion wants to commit, the database checks whether any of the ignored writes have now been committed. If so, the transaction must be aborted.</p>
<p>By avoiding unnecessary aborts, SSI preserves snapshot isolation’s support for long-running reads from a consistent snapshot.</p>
<h5 id="Detecting-writes-that-affect-prior-reads"><a href="#Detecting-writes-that-affect-prior-reads" class="headerlink" title="Detecting writes that affect prior reads"></a>Detecting writes that affect prior reads</h5><p>When a transaction writes to the database, it must look in the indexes for any other transactions that have recently read the affected data. This process is similar to acquiring a write lock on the affected key range, but rather than blocking until the readers have committed, the lock acts as a tripwire: it simply notifies the transactions that the data they read may no longer be up to date.</p>
<h5 id="Performance-of-serializable-snapshot-isolation"><a href="#Performance-of-serializable-snapshot-isolation" class="headerlink" title="Performance of serializable snapshot isolation"></a>Performance of serializable snapshot isolation</h5><p>As always, many engineering details affect how well an algorithm works in practice. For example, one trade-off is the granularity at which transactions’ reads and writes are tracked. Less detailed tracking is faster, but may lead to more transac‐ tions being aborted than strictly necessary.</p>
<p>In some cases, it’s okay for a transaction to read information that was overwritten by another transaction: depending on what else happened, it’s sometimes possible to prove that the result of the execution is nevertheless serializable. PostgreSQL uses this theory to reduce the number of unnecessary aborts.</p>
<p>Compared to two-phase locking, the big advantage of serializable snapshot isolation is that one transaction doesn’t need to block waiting for locks held by another transaction. </p>
<p>The rate of aborts significantly affects the overall performance of SSI.</p>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>…</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://rezelchen.github.io/2020/08/12/DDIA6/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="Ray Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ray Chen's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/2020/08/12/DDIA6/" class="post-title-link" itemprop="url">Note for DDIA in Chapter 6</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-08-12 21:43:00" itemprop="dateCreated datePublished" datetime="2020-08-12T21:43:00+00:00">2020-08-12</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-08-13 11:53:41" itemprop="dateModified" datetime="2020-08-13T11:53:41+00:00">2020-08-13</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Partitioning"><a href="#Partitioning" class="headerlink" title="Partitioning"></a>Partitioning</h2><p>In this chapter we will first look at different approaches for partitioning large datasets and observe how the indexing of data interacts with partitioning. We’ll then talk about rebalancing, which is necessary if you want to add or remove nodes in your cluster. Finally, we’ll get an overview of how databases route requests to the right par‐ titions and execute queries.</p>
<h3 id="Partitioning-and-Replication"><a href="#Partitioning-and-Replication" class="headerlink" title="Partitioning and Replication"></a>Partitioning and Replication</h3><h3 id="Partitioning-of-Key-Value-Data"><a href="#Partitioning-of-Key-Value-Data" class="headerlink" title="Partitioning of Key-Value Data"></a>Partitioning of Key-Value Data</h3><h4 id="Partitioning-by-Key-Range"><a href="#Partitioning-by-Key-Range" class="headerlink" title="Partitioning by Key Range"></a>Partitioning by Key Range</h4><p>This partitioning strategy is used by Bigtable, its open source equivalent HBase, RethinkDB, and MongoDB before version 2.4.</p>
<p>Within each partition, we can keep keys in sorted order. This has the advantage that range scans are easy, and you can treat the key as a concatenated index in order to fetch several related records in one query.</p>
<p>However, the downside of key range partitioning is that certain access patterns can lead to <em>hot spots</em>.</p>
<h4 id="Partitioning-by-Hash-of-Key"><a href="#Partitioning-by-Hash-of-Key" class="headerlink" title="Partitioning by Hash of Key"></a>Partitioning by Hash of Key</h4><p>A good hash function takes skewed data and makes it uniformly distributed. </p>
<p>For partitioning purposes, the hash function need not be cryptographically strong: for example, Cassandra and MongoDB use MD5, and Voldemort uses the Fowler– Noll–Vo function. </p>
<p>Unfortunately however, by using the hash of the key for partitioning we lose a nice property of key-range partitioning: the ability to do efficient range queries. </p>
<h4 id="Skewed-Workloads-and-Relieving-Hot-Spots"><a href="#Skewed-Workloads-and-Relieving-Hot-Spots" class="headerlink" title="Skewed Workloads and Relieving Hot Spots"></a>Skewed Workloads and Relieving Hot Spots</h4><h3 id="Partitioning-and-Secondary-Indexes"><a href="#Partitioning-and-Secondary-Indexes" class="headerlink" title="Partitioning and Secondary Indexes"></a>Partitioning and Secondary Indexes</h3><p>The problem with secondary indexes is that they don’t map neatly to partitions. There are two main approaches to partitioning a database with secondary indexes: document-based partitioning and term-based partitioning.</p>
<h4 id="Partitioning-Secondary-Indexes-by-Document"><a href="#Partitioning-Secondary-Indexes-by-Document" class="headerlink" title="Partitioning Secondary Indexes by Document"></a>Partitioning Secondary Indexes by Document</h4><p>In this indexing approach, each partition is completely separate: each partition main‐ tains its own secondary indexes, covering only the documents in that partition. For that reason, a document-partitioned index is also known as a local index (as opposed to a global index, described in the next section).</p>
<p>You need to send the query to all partitions, and combine all the results you get back.</p>
<p>This approach to querying a partitioned database is sometimes known as <em>scatter/ gather</em>, and it can make read queries on secondary indexes quite expensive. </p>
<h4 id="Partitioning-Secondary-Indexes-by-Term"><a href="#Partitioning-Secondary-Indexes-by-Term" class="headerlink" title="Partitioning Secondary Indexes by Term"></a>Partitioning Secondary Indexes by Term</h4><p>A global index must also be partitioned, but it can be partitioned differently from the primary key index.</p>
<p>We call this kind of index <em>term-partitioned</em>, because the term we’re looking for determines the partition of the index. </p>
<p>The advantage of a global (term-partitioned) index over a document-partitioned index is that it can make reads more efficient: rather than doing scatter/gather over all partitions, a client only needs to make a request to the partition containing the term that it wants. However, the downside of a global index is that writes are slower and more complicated, because a write to a single document may now affect multiple partitions of the index (every term in the document might be on a different partition, on a different node).</p>
<p>In practice, updates to global secondary indexes are often asynchronous (that is, if you read the index shortly after a write, the change you just made may not yet be reflected in the index).</p>
<h3 id="Rebalancing-Partitions"><a href="#Rebalancing-Partitions" class="headerlink" title="Rebalancing Partitions"></a>Rebalancing Partitions</h3><p>The process of moving load from one node in the cluster to another is called <em>rebalancing</em>.</p>
<p>No matter which partitioning scheme is used, rebalancing is usually expected to meet some minimum requirements:</p>
<ul>
<li><p>After rebalancing, the load (data storage, read and write requests) should be shared fairly between the nodes in the cluster.</p>
</li>
<li><p>While rebalancing is happening, the database should continue accepting reads and writes.</p>
</li>
<li><p>No more data than necessary should be moved between nodes, to make rebalancing fast and to minimize the network and disk I/O load.</p>
</li>
</ul>
<h4 id="Strategies-for-Rebalancing"><a href="#Strategies-for-Rebalancing" class="headerlink" title="Strategies for Rebalancing"></a>Strategies for Rebalancing</h4><h5 id="How-not-to-do-it-hash-mod-N"><a href="#How-not-to-do-it-hash-mod-N" class="headerlink" title="How not to do it: hash mod N"></a>How not to do it: hash mod N</h5><p>When partitioning by the hash of a key, we said earlier that it’s best to divide the possible hashes into ranges and assign each range to a partition (e.g., assign key to partition 0 if 0 ≤ hash(key) &lt; b0, to partition 1 if b0 ≤ hash(key) &lt; b1, etc.).</p>
<p>The problem with the mod N approach is that if the number of nodes N changes, most of the keys will need to be moved from one node to another. </p>
<h5 id="Fixed-number-of-partitions"><a href="#Fixed-number-of-partitions" class="headerlink" title="Fixed number of partitions"></a>Fixed number of partitions</h5><p>Fortunately, there is a fairly simple solution: create many more partitions than there are nodes, and assign several partitions to each node.  For example, a database running on a cluster of 10 nodes may be split into 1,000 partitions from the outset so that approximately 100 partitions are assigned to each node.</p>
<p>Now, if a node is added to the cluster, the new node can <em>steal</em> a few partitions from every existing node until partitions are fairly distributed once again. If a node is removed from the cluster, the same happens in reverse.</p>
<p>In this configuration, the number of partitions is usually fixed when the database is first set up and not changed afterward. </p>
<h5 id="Dynamic-partitioning"><a href="#Dynamic-partitioning" class="headerlink" title="Dynamic partitioning"></a>Dynamic partitioning</h5><p>For databases that use key range partitioning, a fixed number of partitions with fixed boundaries would be very incon‐ venient: if you got the boundaries wrong, you could end up with all of the data in one partition and all of the other partitions empty.</p>
<p>When a partition grows to exceed a configured size (on HBase, the default is 10 GB), it is split into two partitions so that approximately half of the data ends up on each side of the split. Conversely, if lots of data is deleted and a partition shrinks below some threshold, it can be merged with an adjacent par‐ tition. This process is similar to what happens at the top level of a B-tree.</p>
<p>Each partition is assigned to one node, and each node can handle multiple partitions, like in the case of a fixed number of partitions. After a large partition has been split, one of its two halves can be transferred to another node in order to balance the load.</p>
<p>An advantage of dynamic partitioning is that the number of partitions adapts to the total data volume. </p>
<p>However, a caveat is that an empty database starts off with a single partition, since there is no a priori information about where to draw the partition boundaries. While the dataset is small—until it hits the point at which the first partition is split—all writes have to be processed by a single node while the other nodes sit idle. </p>
<p>Dynamic partitioning is not only suitable for key range–partitioned data, but can equally well be used with hash-partitioned data. </p>
<h5 id="Partitioning-proportionally-to-nodes"><a href="#Partitioning-proportionally-to-nodes" class="headerlink" title="Partitioning proportionally to nodes"></a>Partitioning proportionally to nodes</h5><p>With dynamic partitioning, the number of partitions is proportional to the size of the dataset, since the splitting and merging processes keep the size of each partition between some fixed minimum and maximum. On the other hand, with a fixed number of partitions, the size of each partition is proportional to the size of the dataset. In both of these cases, the number of partitions is independent of the number of nodes.</p>
<p>A third option, used by Cassandra and Ketama, is to make the number of partitions proportional to the number of nodes—in other words, to have a fixed number of partitions <em>per node</em>.</p>
<p>When a new node joins the cluster, it randomly chooses a fixed number of existing partitions to split, and then takes ownership of one half of each of those split partitions while leaving the other half of each partition in place. </p>
<p>Picking partition boundaries randomly requires that hash-based partitioning is used. ndeed, this approach corresponds most closely to the original definition of consistent hashing. Newer hash func‐ tions can achieve a similar effect with lower metadata overhead.</p>
<h4 id="Operations-Automatic-or-Manual-Rebalancing"><a href="#Operations-Automatic-or-Manual-Rebalancing" class="headerlink" title="Operations: Automatic or Manual Rebalancing"></a>Operations: Automatic or Manual Rebalancing</h4><h3 id="Request-Routing"><a href="#Request-Routing" class="headerlink" title="Request Routing"></a>Request Routing</h3><p>Somebody needs to stay on top of those changes in order to answer the question: if I want to read or write the key “foo”, which IP address and port number do I need to connect to?</p>
<p>This is an instance of a more general problem called <em>service discovery</em>, which isn’t limited to just databases. </p>
<p>On a high level, there are a few different approaches to this problem:</p>
<ol>
<li><p>Allow clients to contact any node (e.g., via a round-robin load balancer). If that node coincidentally owns the partition to which the request applies, it can handle the request directly; otherwise, it forwards the request to the appropriate node, receives the reply, and passes the reply along to the client.</p>
</li>
<li><p>Send all requests from clients to a routing tier first, which determines the node that should handle each request and forwards it accordingly. This routing tier does not itself handle any requests; it only acts as a partition-aware load balancer.</p>
</li>
<li><p>Require that clients be aware of the partitioning and the assignment of partitions to nodes. In this case, a client can connect directly to the appropriate node, without any intermediary.</p>
</li>
</ol>
<p>In all cases, the key problem is: how does the component making the routing decision (which may be one of the nodes, or the routing tier, or the client) learn about changes in the assignment of partitions to nodes?</p>
<p>This is a challenging problem, because it is important that all participants agree— otherwise requests would be sent to the wrong nodes and not handled correctly.</p>
<p>Many distributed data systems rely on a separate coordination service such as ZooKeeper to keep track of this cluster metadata. Each node registers itself in ZooKeeper, and ZooKeeper maintains the authoritative mapping of partitions to nodes. Other actors, such as the routing tier or the partitioning-aware client, can subscribe to this information in ZooKeeper. Whenever a partition changes ownership, or a node is added or removed, ZooKeeper notifies the routing tier so that it can keep its routing information up to date.</p>
<p>Cassandra and Riak take a different approach: they use a gossip protocol among the nodes to disseminate any changes in cluster state. Requests can be sent to any node, and that node forwards them to the appropriate node for the requested partition.</p>
<h4 id="Parallel-Query-Execution"><a href="#Parallel-Query-Execution" class="headerlink" title="Parallel Query Execution"></a>Parallel Query Execution</h4><p>So far we have focused on very simple queries that read or write a single key.</p>
<p>However, <em>massively parallel processing</em> (MPP) relational database products, often used for analytics, are much more sophisticated in the types of queries they support. The MPP query optimizer breaks this complex query into a num‐ ber of execution stages and partitions, many of which can be executed in parallel on different nodes of the database cluster. </p>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>…</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://rezelchen.github.io/2020/08/08/DDIA5/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="Ray Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ray Chen's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/2020/08/08/DDIA5/" class="post-title-link" itemprop="url">Note for DDIA in Chapter 5</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-08-08 20:23:00" itemprop="dateCreated datePublished" datetime="2020-08-08T20:23:00+00:00">2020-08-08</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-08-13 11:53:41" itemprop="dateModified" datetime="2020-08-13T11:53:41+00:00">2020-08-13</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Replication"><a href="#Replication" class="headerlink" title="Replication"></a>Replication</h2><p>There are several reasons why you might want to replicate data:</p>
<ul>
<li><p>To keep data geographically close to your users (and thus reduce latency)</p>
</li>
<li><p>To allow the system to continue working even if some of its parts have failed (and thus increase availability)</p>
</li>
<li><p>To scale out the number of machines that can serve read queries (and thus increase read throughput)</p>
<p>We will discuss three popular algorithms for replicating changes between nodes: <em>single-leader</em>, <em>multi-leader</em>, and <em>leaderless</em> replication. Almost all distributed databases use one of these three approaches. </p>
</li>
</ul>
<h3 id="Leaders-and-Followers"><a href="#Leaders-and-Followers" class="headerlink" title="Leaders and Followers"></a>Leaders and Followers</h3><h4 id="Synchronous-Versus-Asynchronous-Replication"><a href="#Synchronous-Versus-Asynchronous-Replication" class="headerlink" title="Synchronous Versus Asynchronous Replication"></a>Synchronous Versus Asynchronous Replication</h4><p>In practice, if you enable synchronous replication on a database, it usually means that <em>one</em> of the followers is synchronous, and the others are asynchronous.</p>
<h4 id="Setting-Up-New-Followers"><a href="#Setting-Up-New-Followers" class="headerlink" title="Setting Up New Followers"></a>Setting Up New Followers</h4><h4 id="Handling-Node-Outages"><a href="#Handling-Node-Outages" class="headerlink" title="Handling Node Outages"></a>Handling Node Outages</h4><h5 id="Follower-failure-Catch-up-recovery"><a href="#Follower-failure-Catch-up-recovery" class="headerlink" title="Follower failure: Catch-up recovery"></a>Follower failure: Catch-up recovery</h5><h5 id="Leader-failure-Failover"><a href="#Leader-failure-Failover" class="headerlink" title="Leader failure: Failover"></a>Leader failure: Failover</h5><p>An automatic failover process usually consists of the following steps:</p>
<ul>
<li><p><em>Determining that the leader has failed.</em></p>
</li>
<li><p><em>Choosing a new leader.</em> The best candidate for leadership is usually the replica with the most up-to-date data changes from the old leader (to minimize any data loss).</p>
</li>
<li><p><em>Reconfiguring the system to use the new leader.</em></p>
</li>
</ul>
<p>Failover is fraught with things that can go wrong:</p>
<ul>
<li><p>If asynchronous replication is used, the new leader may not have received all the writes from the old leader before it failed. If the former leader rejoins the cluster after a new leader has been chosen, what should happen to those writes? The new leader may have received conflicting writes in the meantime. The most common solution is for the old leader’s unreplicated writes to simply be discarded, which may violate clients’ durability expectations.</p>
</li>
<li><p>Discarding writes is especially dangerous if other storage systems outside of the database need to be coordinated with the database contents. </p>
</li>
<li><p>In certain fault scenarios (see Chapter 8), it could happen that two nodes both believe that they are the leader. This situation is called split brain, and it is dan‐ gerous: if both leaders accept writes, and there is no process for resolving con‐ flicts (see “Multi-Leader Replication” on page 168), data is likely to be lost or corrupted. </p>
</li>
<li><p>What is the right timeout before the leader is declared dead? </p>
</li>
</ul>
<h4 id="Implementation-of-Replication-Logs"><a href="#Implementation-of-Replication-Logs" class="headerlink" title="Implementation of Replication Logs"></a>Implementation of Replication Logs</h4><h5 id="Statement-based-replication"><a href="#Statement-based-replication" class="headerlink" title="Statement-based replication"></a>Statement-based replication</h5><p>In the simplest case, the leader logs every write request (statement) that it executes and sends that statement log to its followers. </p>
<p>Although this may sound reasonable, there are various ways in which this approach to replication can break down:</p>
<ul>
<li><p>Any statement that calls a nondeterministic function, such as NOW() to get the current date and time or RAND() to get a random number, is likely to generate a different value on each replica.</p>
</li>
<li><p>If statements use an autoincrementing column, or if they depend on the existing data in the database (e.g., UPDATE … WHERE <some condition>), they must be executed in exactly the same order on each replica, or else they may have a differ‐ ent effect. This can be limiting when there are multiple concurrently executing transactions.</p>
</li>
<li><p>Statements that have side effects (e.g., triggers, stored procedures, user-defined functions) may result in different side effects occurring on each replica, unless the side effects are absolutely deterministic.</p>
</li>
</ul>
<h5 id="Write-ahead-log-WAL-shipping"><a href="#Write-ahead-log-WAL-shipping" class="headerlink" title="Write-ahead log (WAL) shipping"></a>Write-ahead log (WAL) shipping</h5><p>The main disadvantage is that the log describes the data on a very low level: a WAL con‐ tains details of which bytes were changed in which disk blocks. This makes replica‐ tion closely coupled to the storage engine. </p>
<p>That may seem like a minor implementation detail, but it can have a big operational impact. If the replication protocol allows the follower to use a newer software version than the leader, you can perform a zero-downtime upgrade of the database software by first upgrading the followers and then performing a failover to make one of the upgraded nodes the new leader. If the replication protocol does not allow this version mismatch, as is often the case with WAL shipping, such upgrades require downtime.</p>
<h5 id="Logical-row-based-log-replication"><a href="#Logical-row-based-log-replication" class="headerlink" title="Logical (row-based) log replication"></a>Logical (row-based) log replication</h5><p>An alternative is to use different log formats for replication and for the storage engine, which allows the replication log to be decoupled from the storage engine internals. This kind of replication log is called a logical log, to distinguish it from the storage engine’s (physical) data representation.</p>
<p>A logical log for a relational database is usually a sequence of records describing writes to database tables at the granularity of a row:</p>
<ul>
<li><p>For an inserted row, the log contains the new values of all columns.</p>
</li>
<li><p>For a deleted row, the log contains enough information to uniquely identify the row that was deleted. Typically this would be the primary key, but if there is no primary key on the table, the old values of all columns need to be logged.</p>
</li>
<li><p>For an updated row, the log contains enough information to uniquely identify the updated row, and the new values of all columns (or at least the new values of all columns that changed).</p>
</li>
</ul>
<p>A transaction that modifies several rows generates several such log records, followed by a record indicating that the transaction was committed.</p>
<h5 id="Trigger-based-replication"><a href="#Trigger-based-replication" class="headerlink" title="Trigger-based replication"></a>Trigger-based replication</h5><h3 id="Problems-with-Replication-Lag"><a href="#Problems-with-Replication-Lag" class="headerlink" title="Problems with Replication Lag"></a>Problems with Replication Lag</h3><h4 id="Reading-Your-Own-Writes"><a href="#Reading-Your-Own-Writes" class="headerlink" title="Reading Your Own Writes"></a>Reading Your Own Writes</h4><p><em>read-after-write consistency</em><br><em>cross-device read-after-write consistency</em></p>
<h4 id="Monotonic-Reads"><a href="#Monotonic-Reads" class="headerlink" title="Monotonic Reads"></a>Monotonic Reads</h4><p>When you read data, you may see an old value; monotonic reads only means that if one user makes several reads in sequence, they will not see time go backward— i.e., they will not read older data after having previously read newer data.</p>
<p>One way of achieving monotonic reads is to make sure that each user always makes their reads from the same replica.</p>
<h4 id="Consistent-Prefix-Reads"><a href="#Consistent-Prefix-Reads" class="headerlink" title="Consistent Prefix Reads"></a>Consistent Prefix Reads</h4><p>This guarantee says that if a sequence of writes happens in a certain order, then anyone reading those writes will see them appear in the same order.</p>
<h4 id="Solutions-for-Replication-Lag"><a href="#Solutions-for-Replication-Lag" class="headerlink" title="Solutions for Replication Lag"></a>Solutions for Replication Lag</h4><h3 id="Multi-Leader-Replication"><a href="#Multi-Leader-Replication" class="headerlink" title="Multi-Leader Replication"></a>Multi-Leader Replication</h3><h4 id="Use-Cases-for-Multi-Leader-Replication"><a href="#Use-Cases-for-Multi-Leader-Replication" class="headerlink" title="Use Cases for Multi-Leader Replication"></a>Use Cases for Multi-Leader Replication</h4><h5 id="Multi-datacenter-operation"><a href="#Multi-datacenter-operation" class="headerlink" title="Multi-datacenter operation"></a>Multi-datacenter operation</h5><p>Although multi-leader replication has advantages, it also has a big downside: the same data may be concurrently modified in two different datacenters, and those write conflicts must be resolved.</p>
<h5 id="Clients-with-offline-operation"><a href="#Clients-with-offline-operation" class="headerlink" title="Clients with offline operation"></a>Clients with offline operation</h5><p>Another situation in which multi-leader replication is appropriate is if you have an application that needs to continue to work while it is disconnected from the internet.</p>
<p>In this case, every device has a local database that acts as a leader (it accepts write requests), and there is an asynchronous multi-leader replication process (sync) between the replicas of your calendar on all of your devices. The replication lag may be hours or even days, depending on when you have internet access available.</p>
<p>There are tools that aim to make this kind of multi-leader configuration easier. For example, CouchDB is designed for this mode of operation.</p>
<h5 id="Collaborative-editing"><a href="#Collaborative-editing" class="headerlink" title="Collaborative editing"></a>Collaborative editing</h5><p><em>Real-time collaborative editing</em> applications allow several people to edit a document simultaneously. </p>
<p>We don’t usually think of collaborative editing as a database replication problem, but it has a lot in common with the previously mentioned offline editing use case. </p>
<h4 id="Handling-Write-Conflicts"><a href="#Handling-Write-Conflicts" class="headerlink" title="Handling Write Conflicts"></a>Handling Write Conflicts</h4><h5 id="Synchronous-versus-asynchronous-conflict-detection"><a href="#Synchronous-versus-asynchronous-conflict-detection" class="headerlink" title="Synchronous versus asynchronous conflict detection"></a>Synchronous versus asynchronous conflict detection</h5><p>In a single-leader database, the second writer will either block and wait for the first write to complete, or abort the second write transaction, forcing the user to retry the write. On the other hand, in a multi-leader setup, both writes are successful, and the conflict is only detected asynchronously at some later point in time. At that time, it may be too late to ask the user to resolve the conflict.</p>
<h5 id="Conflict-avoidance"><a href="#Conflict-avoidance" class="headerlink" title="Conflict avoidance"></a>Conflict avoidance</h5><p>The simplest strategy for dealing with conflicts is to avoid them: if the application can ensure that all writes for a particular record go through the same leader, then con‐ flicts cannot occur. </p>
<h5 id="Converging-toward-a-consistent-state"><a href="#Converging-toward-a-consistent-state" class="headerlink" title="Converging toward a consistent state"></a>Converging toward a consistent state</h5><p>That is not acceptable—every replication scheme must ensure that the data is eventually the same in all replicas. Thus, the database must resolve the conflict in a <em>convergent</em> way, which means that all replicas must arrive at the same final value when all changes have been replicated.</p>
<p>There are various ways of achieving convergent conflict resolution:</p>
<ul>
<li><p>Give each write a unique ID (e.g., a timestamp, a long random number, a UUID, or a hash of the key and value), pick the write with the highest ID as the <em>winner</em>, and throw away the other writes. If a timestamp is used, this technique is known as <em>last write wins</em> (LWW). Although this approach is popular, it is dangerously prone to data loss.</p>
</li>
<li><p>Give each replica a unique ID, and let writes that originated at a higher- numbered replica always take precedence over writes that originated at a lower- numbered replica. This approach also implies data loss.</p>
</li>
<li><p>Somehow merge the values together—e.g., order them alphabetically and then concatenate them.</p>
</li>
<li><p>Record the conflict in an explicit data structure that preserves all information, and write application code that resolves the conflict at some later time.</p>
</li>
</ul>
<h5 id="Custom-conflict-resolution-logic"><a href="#Custom-conflict-resolution-logic" class="headerlink" title="Custom conflict resolution logic"></a>Custom conflict resolution logic</h5><p>That code may be executed on write or on read:</p>
<p>On write: As soon as the database system detects a conflict in the log of replicated changes, it calls the conflict handler.</p>
<p>On read: When a conflict is detected, all the conflicting writes are stored. The next time the data is read, these multiple versions of the data are returned to the application. The application may prompt the user or automatically resolve the conflict, and write the result back to the database. </p>
<p>There has been some interesting research into automatically resolving conflicts caused by concurrent data modifications. A few lines of research are worth mentioning:</p>
<ul>
<li><p><em>Conflict-free replicated datatypes</em> (CRDTs) are a family of data structures for sets, maps, ordered lists, counters, etc. that can be concurrently edited by multiple users, and which automatically resolve conflicts in sensible ways. Some CRDTs have been implemented in Riak 2.0.</p>
</li>
<li><p><em>Mergeable persistent data structures</em> track history explicitly, similarly to the Git version control system, and use a three-way merge function (whereas CRDTs use two-way merges).</p>
</li>
<li><p><em>Operational transformation</em> is the conflict resolution algorithm behind col‐ laborative editing applications such as Etherpad and Google Docs. It was designed particularly for concurrent editing of an ordered list of items, such as the list of characters that constitute a text document.</p>
</li>
</ul>
<h5 id="What-is-a-conflict"><a href="#What-is-a-conflict" class="headerlink" title="What is a conflict?"></a>What is a conflict?</h5><h4 id="Multi-Leader-Replication-Topologies"><a href="#Multi-Leader-Replication-Topologies" class="headerlink" title="Multi-Leader Replication Topologies"></a>Multi-Leader Replication Topologies</h4><p>A problem with <em>circular and star topologies</em> is that if just one node fails, it can inter‐ rupt the flow of replication messages between other nodes, causing them to be unable to communicate until the node is fixed.</p>
<p>On the other hand, <em>all-to-all topologies</em> can have issues too. In particular, some network links may be faster than others (e.g., due to network congestion), with the result that some replication messages may “overtake” others.</p>
<h3 id="Leaderless-Replication"><a href="#Leaderless-Replication" class="headerlink" title="Leaderless Replication"></a>Leaderless Replication</h3><p>It once again became a fashiona‐ ble architecture for databases after Amazon used it for its in-house Dynamo system. Riak, Cassandra, and Voldemort are open source datastores with leaderless replication models inspired by Dynamo, so this kind of database is also known as Dynamo-style.</p>
<h4 id="Writing-to-the-Database-When-a-Node-Is-Down"><a href="#Writing-to-the-Database-When-a-Node-Is-Down" class="headerlink" title="Writing to the Database When a Node Is Down"></a>Writing to the Database When a Node Is Down</h4><h5 id="Read-repair-and-anti-entropy"><a href="#Read-repair-and-anti-entropy" class="headerlink" title="Read repair and anti-entropy"></a>Read repair and anti-entropy</h5><p>Two mechanisms are often used in Dynamo-style datastores:</p>
<ul>
<li>Read repair</li>
<li>Anti-entropy process</li>
</ul>
<p>Not all systems implement both of these; for example, Voldemort currently does not have an anti-entropy process. Note that without an anti-entropy process, values that are rarely read may be missing from some replicas and thus have reduced durability, because read repair is only performed when a value is read by the application.</p>
<h5 id="Quorums-for-reading-and-writing"><a href="#Quorums-for-reading-and-writing" class="headerlink" title="Quorums for reading and writing"></a>Quorums for reading and writing</h5><p>More generally, if there are n replicas, every write must be confirmed by w nodes to be considered successful, and we must query at least r nodes for each read. (In our example, n = 3, w = 2, r = 2.)</p>
<p>You can think of r and w as the minimum number of votes required for the read or write to be valid.</p>
<h4 id="Limitations-of-Quorum-Consistency"><a href="#Limitations-of-Quorum-Consistency" class="headerlink" title="Limitations of Quorum Consistency"></a>Limitations of Quorum Consistency</h4><p>However, even with w + r &gt; n, there are likely to be edge cases where stale values are returned. These depend on the implementation, but possible scenarios include:</p>
<ul>
<li><p>If a sloppy quorum is used, the w writes may end up on different nodes than the r reads, so there is no longer a guaranteed overlap between the r nodes and the w nodes.</p>
</li>
<li><p>If two writes occur concurrently, it is not clear which one happened first. In this case, the only safe solution is to merge the concurrent writes.</p>
</li>
<li><p>If a write happens concurrently with a read, the write may be reflected on only some of the replicas. In this case, it’s undetermined whether the read returns the old or the new value.</p>
</li>
<li><p>If a write succeeded on some replicas but failed on others (for example because the disks on some nodes are full), and overall succeeded on fewer than w replicas, it is not rolled back on the replicas where it succeeded. This means that if a write was reported as failed, subsequent reads may or may not return the value from that write.</p>
</li>
<li><p>If a node carrying a new value fails, and its data is restored from a replica carrying an old value, the number of replicas storing the new value may fall below w, breaking the quorum condition.</p>
</li>
<li><p>Even if everything is working correctly, there are edge cases in which you can get unlucky with the timing, as we shall see in “Linearizability and quorums” on page 334.</p>
</li>
</ul>
<p>In particular, you usually do not get the guarantees discussed in “Problems with Replication Lag” on page 161 (reading your writes, monotonic reads, or consistent prefix reads), so the previously mentioned anomalies can occur in applications. Stronger guarantees generally require transactions or consensus. </p>
<h5 id="Monitoring-staleness"><a href="#Monitoring-staleness" class="headerlink" title="Monitoring staleness"></a>Monitoring staleness</h5><h4 id="Sloppy-Quorums-and-Hinted-Handoff"><a href="#Sloppy-Quorums-and-Hinted-Handoff" class="headerlink" title="Sloppy Quorums and Hinted Handoff"></a>Sloppy Quorums and Hinted Handoff</h4><p><em>Sloppy quorum</em>: writes and reads still require w and r successful responses, but those may include nodes that are not among the designated n “home” nodes for a value. </p>
<p>Once the network interruption is fixed, any writes that one node temporarily accepted on behalf of another node are sent to the appropriate “home” nodes. This is called <em>hinted handoff</em>.</p>
<p>Sloppy quorums are particularly useful for increasing write availability: as long as any w nodes are available, the database can accept writes. However, this means that even when w + r &gt; n, you cannot be sure to read the latest value for a key, because the latest value may have been temporarily written to some nodes outside of n.</p>
<p>Thus, a sloppy quorum actually isn’t a quorum at all in the traditional sense. It’s only an assurance of durability, namely that the data is stored on w nodes somewhere. There is no guarantee that a read of r nodes will see it until the hinted handoff has completed.</p>
<h5 id="Multi-datacenter-operation-1"><a href="#Multi-datacenter-operation-1" class="headerlink" title="Multi-datacenter operation"></a>Multi-datacenter operation</h5><h4 id="Detecting-Concurrent-Writes"><a href="#Detecting-Concurrent-Writes" class="headerlink" title="Detecting Concurrent Writes"></a>Detecting Concurrent Writes</h4><p>Dynamo-style databases allow several clients to concurrently write to the same key, which means that conflicts will occur even if strict quorums are used.</p>
<p>The problem is that events may arrive in a different order at different nodes, due to variable network delays and partial failures. </p>
<h5 id="Last-write-wins-discarding-concurrent-writes"><a href="#Last-write-wins-discarding-concurrent-writes" class="headerlink" title="Last write wins (discarding concurrent writes)"></a>Last write wins (discarding concurrent writes)</h5><p>One approach for achieving eventual convergence is to declare that each replica need only store the most “recent” value and allow “older” values to be overwritten and dis‐ carded. Then, as long as we have some way of unambiguously determining which write is more “recent,” and every write is eventually copied to every replica, the repli‐ cas will eventually converge to the same value.</p>
<p>Even though the writes don’t have a natural ordering, we can force an arbitrary order on them. For example, we can attach a timestamp to each write, pick the biggest timestamp as the most “recent,” and discard any writes with an earlier timestamp.</p>
<h5 id="The-“happens-before”-relationship-and-concurrency"><a href="#The-“happens-before”-relationship-and-concurrency" class="headerlink" title="The “happens-before” relationship and concurrency"></a>The “happens-before” relationship and concurrency</h5><p>An operation A <em>happens before</em> another operation B if B knows about A, or depends on A, or builds upon A in some way. Whether one operation happens before another operation is the key to defining what concurrency means. In fact, we can simply say that two operations are concurrent if neither happens before the other (i.e., neither knows about the other)</p>
<h5 id="Capturing-the-happens-before-relationship"><a href="#Capturing-the-happens-before-relationship" class="headerlink" title="Capturing the happens-before relationship"></a>Capturing the happens-before relationship</h5><p>Note that the server can determine whether two operations are concurrent by looking at the version numbers—it does not need to interpret the value itself (so the value could be any data structure). The algorithm works as follows:</p>
<ul>
<li><p>The server maintains a version number for every key, increments the version number every time that key is written, and stores the new version number along with the value written.</p>
</li>
<li><p>When a client reads a key, the server returns all values that have not been overwritten, as well as the latest version number. A client must read a key before writing.</p>
</li>
<li><p>When a client writes a key, it must include the version number from the prior read, and it must merge together all values that it received in the prior read. (The response from a write request can be like a read, returning all current values, which allows us to chain several writes like in the shopping cart example.)</p>
</li>
<li><p>When the server receives a write with a particular version number, it can over‐ write all values with that version number or below (since it knows that they have been merged into the new value), but it must keep all values with a higher ver‐ sion number (because those values are concurrent with the incoming write).</p>
</li>
</ul>
<p>When a write includes the version number from a prior read, that tells us which pre‐ vious state the write is based on. If you make a write without including a version number, it is concurrent with all other writes, so it will not overwrite anything—it will just be returned as one of the values on subsequent reads.</p>
<h5 id="Merging-concurrently-written-values"><a href="#Merging-concurrently-written-values" class="headerlink" title="Merging concurrently written values"></a>Merging concurrently written values</h5><p>Merging sibling values is essentially the same problem as conflict resolution in multi- leader replication, which we discussed previously (see “Handling Write Conflicts” on page 171). A simple approach is to just pick one of the values based on a version number or timestamp (last write wins), but that implies losing data. So, you may need to do something more intelligent in application code.</p>
<p>However, if you want to allow people to also remove things from their carts, and not just add things, then taking the union of siblings may not yield the right result.</p>
<p>To prevent this problem, an item cannot simply be deleted from the database when it is removed; instead, the system must leave a marker with an appropriate version number to indicate that the item has been removed when merging siblings. Such a deletion marker is known as a <em>tombstone</em>.</p>
<h5 id="Version-vectors"><a href="#Version-vectors" class="headerlink" title="Version vectors"></a>Version vectors</h5><p>The collection of version numbers from all the replicas is called a version vector.</p>
<h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>…</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://rezelchen.github.io/2020/07/28/DDIA4/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="Ray Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ray Chen's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/2020/07/28/DDIA4/" class="post-title-link" itemprop="url">Note for DDIA in Chapter 4</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-07-28 17:38:00" itemprop="dateCreated datePublished" datetime="2020-07-28T17:38:00+00:00">2020-07-28</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-08-13 11:53:41" itemprop="dateModified" datetime="2020-08-13T11:53:41+00:00">2020-08-13</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Encoding-and-Evolution"><a href="#Encoding-and-Evolution" class="headerlink" title="Encoding and Evolution"></a>Encoding and Evolution</h2><h3 id="Formats-for-Encoding-Data"><a href="#Formats-for-Encoding-Data" class="headerlink" title="Formats for Encoding Data"></a>Formats for Encoding Data</h3><h4 id="Language-Specific-Formats"><a href="#Language-Specific-Formats" class="headerlink" title="Language-Specific Formats"></a>Language-Specific Formats</h4><p>It’s generally a bad idea to use your language’s built-in encoding for anything other than very transient purposes.</p>
<h4 id="JSON-XML-and-Binary-Variants"><a href="#JSON-XML-and-Binary-Variants" class="headerlink" title="JSON, XML, and Binary Variants"></a>JSON, XML, and Binary Variants</h4><h5 id="Binary-encoding"><a href="#Binary-encoding" class="headerlink" title="Binary encoding"></a>Binary encoding</h5><h4 id="Thrift-and-Protocol-Buffers"><a href="#Thrift-and-Protocol-Buffers" class="headerlink" title="Thrift and Protocol Buffers"></a>Thrift and Protocol Buffers</h4><p>…</p>
<h4 id="Avro"><a href="#Avro" class="headerlink" title="Avro"></a>Avro</h4><p>…</p>
<h4 id="The-Merits-of-Schemas"><a href="#The-Merits-of-Schemas" class="headerlink" title="The Merits of Schemas"></a>The Merits of Schemas</h4><ul>
<li><p>They can be much more compact than the various “binary JSON” variants, since they can omit field names from the encoded data.</p>
</li>
<li><p>The schema is a valuable form of documentation, and because the schema is required for decoding, you can be sure that it is up to date (whereas manually maintained documentation may easily diverge from reality).</p>
</li>
<li><p>Keeping a database of schemas allows you to check forward and backward com‐ patibility of schema changes, before anything is deployed.</p>
</li>
<li><p>For users of statically typed programming languages, the ability to generate code from the schema is useful, since it enables type checking at compile time.</p>
</li>
</ul>
<p>In summary, schema evolution allows the same kind of flexibility as schemaless/schema-on-read JSON databases provide, while also providing better guarantees about your data and better tooling.</p>
<h3 id="Modes-of-Dataflow"><a href="#Modes-of-Dataflow" class="headerlink" title="Modes of Dataflow"></a>Modes of Dataflow</h3><h4 id="Dataflow-Through-Databases"><a href="#Dataflow-Through-Databases" class="headerlink" title="Dataflow Through Databases"></a>Dataflow Through Databases</h4><h5 id="Different-values-written-at-different-times"><a href="#Different-values-written-at-different-times" class="headerlink" title="Different values written at different times"></a>Different values written at different times</h5><p>Schema evolution thus allows the entire database to appear as if it was encoded with a single schema, even though the underlying storage may contain records encoded with various historical versions of the schema.</p>
<h5 id="Archival-storage"><a href="#Archival-storage" class="headerlink" title="Archival storage"></a>Archival storage</h5><h4 id="Dataflow-Through-Services-REST-and-RPC"><a href="#Dataflow-Through-Services-REST-and-RPC" class="headerlink" title="Dataflow Through Services: REST and RPC"></a>Dataflow Through Services: REST and RPC</h4><h5 id="Web-services"><a href="#Web-services" class="headerlink" title="Web services"></a>Web services</h5><h5 id="The-problems-with-remote-procedure-calls-RPCs"><a href="#The-problems-with-remote-procedure-calls-RPCs" class="headerlink" title="The problems with remote procedure calls (RPCs)"></a>The problems with remote procedure calls (RPCs)</h5><p>Although RPC seems convenient at first, the approach is fundamentally flawed. A network request is very different from a local function call:</p>
<ul>
<li><p>A local function call is predictable and either succeeds or fails, depending only on parameters that are under your control. A network request is unpredictable: the request or response may be lost due to a network problem, or the remote machine may be slow or unavailable, and such problems are entirely outside of your control. </p>
</li>
<li><p>A network request has another possible outcome: it may return without a result, due to a timeout. </p>
</li>
<li><p>If you retry a failed network request, it could happen that the requests are actually getting through, and only the responses are getting lost. In that case, retrying will cause the action to be performed multiple times, unless you build a mechanism for deduplication (idempotence) into the protocol.</p>
</li>
<li><p>A network request is much slower than a function call, and its latency is also wildly variable.</p>
</li>
<li><p>When you call a local function, you can efficiently pass it references (pointers) to objects in local memory. When you make a network request, all those parameters need to be encoded into a sequence of bytes that can be sent over the network.</p>
</li>
<li><p>The client and the service may be implemented in different programming lan‐ guages, so the RPC framework must translate datatypes from one language into another.</p>
</li>
</ul>
<h5 id="Current-directions-for-RPC"><a href="#Current-directions-for-RPC" class="headerlink" title="Current directions for RPC"></a>Current directions for RPC</h5><p>The main focus of RPC frameworks is on requests between services owned by the same organization, typically within the same datacenter.</p>
<h5 id="Data-encoding-and-evolution-for-RPC"><a href="#Data-encoding-and-evolution-for-RPC" class="headerlink" title="Data encoding and evolution for RPC"></a>Data encoding and evolution for RPC</h5><p>We can make a simplifying assumption in the case of dataflow through services: it is reasonable to assume that all the servers will be updated first, and all the clients second. Thus, you only need backward compatibility on requests, and forward compatibility on responses.</p>
<p>If a compatibility-breaking change is required, the service provider often ends up maintaining multiple versions of the service API side by side.</p>
<h4 id="Message-Passing-Dataflow"><a href="#Message-Passing-Dataflow" class="headerlink" title="Message-Passing Dataflow"></a>Message-Passing Dataflow</h4><p>Using a message broker has several advantages compared to direct RPC:</p>
<ul>
<li><p>It can act as a buffer if the recipient is unavailable or overloaded, and thus improve system reliability.</p>
</li>
<li><p>It can automatically redeliver messages to a process that has crashed, and thus prevent messages from being lost.</p>
</li>
<li><p>It avoids the sender needing to know the IP address and port number of the recipient.</p>
</li>
<li><p>It allows one message to be sent to several recipients.</p>
</li>
<li><p>It logically decouples the sender from the recipient.</p>
</li>
</ul>
<p>However, a difference compared to RPC is that message-passing communication is usually one-way: a sender normally doesn’t expect to receive a reply to its messages. </p>
<h5 id="Message-brokers"><a href="#Message-brokers" class="headerlink" title="Message brokers"></a>Message brokers</h5><h5 id="Distributed-actor-frameworks"><a href="#Distributed-actor-frameworks" class="headerlink" title="Distributed actor frameworks"></a>Distributed actor frameworks</h5><p>The <em>actor model</em> is a programming model for concurrency in a single process. Each actor typically represents one client or entity, it may have some local state, and it communicates with other actors by sending and receiving asynchronous messages. Message delivery is not guaranteed: in certain error scenarios, mes‐ sages will be lost. Since each actor processes only one message at a time, it doesn’t need to worry about threads, and each actor can be scheduled independently by the framework.</p>
<p>In <em>distributed actor frameworks</em>, this programming model is used to scale an applica‐ tion across multiple nodes. The same message-passing mechanism is used, no matter whether the sender and recipient are on the same node or different nodes. </p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://rezelchen.github.io/2020/07/24/DDIA3/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="Ray Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ray Chen's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/2020/07/24/DDIA3/" class="post-title-link" itemprop="url">Note for DDIA in Chapter 3</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-07-24 23:05:00" itemprop="dateCreated datePublished" datetime="2020-07-24T23:05:00+00:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-08-13 11:53:41" itemprop="dateModified" datetime="2020-08-13T11:53:41+00:00">2020-08-13</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Storage-and-Retrieval"><a href="#Storage-and-Retrieval" class="headerlink" title="Storage and Retrieval"></a>Storage and Retrieval</h2><p>We will examine two families of storage engines: <em>log-structured</em> storage engines, and <em>page-oriented</em> storage engines such as B-trees.</p>
<h3 id="Data-Structures-That-Power-Your-Database"><a href="#Data-Structures-That-Power-Your-Database" class="headerlink" title="Data Structures That Power Your Database"></a>Data Structures That Power Your Database</h3><h4 id="Hash-Indexes"><a href="#Hash-Indexes" class="headerlink" title="Hash Indexes"></a>Hash Indexes</h4><p>Segments are never modified after they have been written, so the merged segment is written to a new file. The merging and compaction of frozen segments can be done in a background thread, and while it is going on, we can still continue to serve read and write requests as normal, using the old segment files. After the merging process is complete, we switch read requests to using the new merged segment instead of the old segments — and then the old segment files can simply be deleted.</p>
<p>Each segment now has its own in-memory hash table, mapping keys to file offsets. </p>
<p>An append-only design turns out to be good for several reasons:</p>
<ul>
<li><p>Appending and segment merging are sequential write operations, which are generally much faster than random writes, especially on magnetic spinning-disk hard drives.</p>
</li>
<li><p>Concurrency and crash recovery are much simpler if segment files are append-only or immutable.</p>
</li>
<li><p>Merging old segments avoids the problem of data files getting fragmented over time.</p>
</li>
</ul>
<p>The hash table index also has limitations:</p>
<ul>
<li>The hash table must fit in memory, so if you have a very large number of keys, you’re out of luck.</li>
<li>Range queries are not efficient. </li>
</ul>
<h4 id="SSTables-and-LSM-Trees"><a href="#SSTables-and-LSM-Trees" class="headerlink" title="SSTables and LSM-Trees"></a>SSTables and LSM-Trees</h4><p>SSTables have several big advantages over log segments with hash indexes:</p>
<ul>
<li><p>Merging segments is simple and efficient, even if the files are bigger than the available memory. The approach is like the one used in the <em>mergesort</em> algorithm</p>
</li>
<li><p>In order to find a particular key in the file, you no longer need to keep an index of all the keys in memory. You still need an in-memory index to tell you the offsets for some of the keys, but it can be sparse: one key for every few kilobytes of segment file is sufficient, because a few kilobytes can be scanned very quickly.i</p>
</li>
<li><p>Since read requests need to scan over several key-value pairs in the requested range anyway, it is possible to group those records into a block and compress it before writing it to disk. Each entry of the sparse in-memory index then points at the start of a compressed block.</p>
</li>
</ul>
<h5 id="Constructing-and-maintaining-SSTables"><a href="#Constructing-and-maintaining-SSTables" class="headerlink" title="Constructing and maintaining SSTables"></a>Constructing and maintaining SSTables</h5><ul>
<li><p>When a write comes in, add it to an in-memory balanced tree data structure (for<br>example, a red-black tree). This in-memory tree is sometimes called a memtable.</p>
</li>
<li><p>When the memtable gets bigger than some threshold—typically a few megabytes—write it out to disk as an SSTable file. This can be done efficiently because the tree already maintains the key-value pairs sorted by key. The new SSTable file becomes the most recent segment of the database. While the SSTable is being written out to disk, writes can continue to a new memtable instance.</p>
</li>
<li><p>In order to serve a read request, first try to find the key in the memtable, then in the most recent on-disk segment, then in the next-older segment, etc.</p>
</li>
<li><p>From time to time, run a merging and compaction process in the background to combine segment files and to discard overwritten or deleted values.</p>
</li>
</ul>
<p>This scheme works very well. It only suffers from one problem: if the database crashes, the most recent writes (which are in the memtable but not yet written out to disk) are lost. In order to avoid that problem, we can keep a separate log on disk to which every write is immediately appended, just like in the previous section. That log is not in sorted order, but that doesn’t matter, because its only purpose is to restore the memtable after a crash. Every time the memtable is written out to an SSTable, the corresponding log can be discarded.</p>
<h5 id="Making-an-LSM-tree-out-of-SSTables"><a href="#Making-an-LSM-tree-out-of-SSTables" class="headerlink" title="Making an LSM-tree out of SSTables"></a>Making an LSM-tree out of SSTables</h5><h5 id="Performance-optimizations"><a href="#Performance-optimizations" class="headerlink" title="Performance optimizations"></a>Performance optimizations</h5><p>The LSM-tree algorithm can be slow when looking up keys that do not exist in the database. In order to optimize this kind of access, storage engines often use additional <em>Bloom filters</em>.</p>
<p>There are also different strategies to determine the order and timing of how SSTables are compacted and merged. The most common options are <em>size-tiered</em> and <em>leveled</em> compaction.</p>
<h4 id="B-Trees"><a href="#B-Trees" class="headerlink" title="B-Trees"></a>B-Trees</h4><p>Like SSTables, B-trees keep key-value pairs sorted by key, which allows efficient key- value lookups and range queries.</p>
<p>B-trees break the database down into fixed-size blocks or pages, traditionally 4 KB in size (sometimes bigger), and read or write one page at a time. </p>
<p>Each page can be identified using an address or location, which allows one page to refer to another—similar to a pointer, but on disk instead of in memory. </p>
<h5 id="Making-B-trees-reliable"><a href="#Making-B-trees-reliable" class="headerlink" title="Making B-trees reliable"></a>Making B-trees reliable</h5><p>In order to make the database resilient to crashes, it is common for B-tree implemen‐ tations to include an additional data structure on disk: a write-ahead log (WAL, also known as a redo log). </p>
<p>An additional complication of updating pages in place is that careful concurrency control is required if multiple threads are going to access the B-tree at the same time —otherwise a thread may see the tree in an inconsistent state. This is typically done by protecting the tree’s data structures with <em>latches</em> (lightweight locks).</p>
<h5 id="B-tree-optimizations"><a href="#B-tree-optimizations" class="headerlink" title="B-tree optimizations"></a>B-tree optimizations</h5><ul>
<li><p>Instead of overwriting pages and maintaining a WAL for crash recovery, some databases (like LMDB) use a copy-on-write scheme. A modified page is written to a different location, and a new version of the parent pages in the tree is created, pointing at the new location. </p>
</li>
<li><p>We can save space in pages by not storing the entire key, but abbreviating it.</p>
</li>
<li><p>If a query needs to scan over a large part of the key range in sorted order, that page-by-page layout can be ineffi‐ cient, because a disk seek may be required for every page that is read. Many B- tree implementations therefore try to lay out the tree so that leaf pages appear in sequential order on disk. </p>
</li>
<li><p>Additional pointers have been added to the tree. For example, each leaf page may have references to its sibling pages to the left and right, which allows scanning keys in order without jumping back to parent pages.</p>
</li>
<li><p>B-tree variants such as fractal trees borrow some log-structured ideas to reduce disk seeks (and they have nothing to do with fractals).</p>
</li>
</ul>
<h4 id="Comparing-B-Trees-and-LSM-Trees"><a href="#Comparing-B-Trees-and-LSM-Trees" class="headerlink" title="Comparing B-Trees and LSM-Trees"></a>Comparing B-Trees and LSM-Trees</h4><h5 id="Advantages-of-LSM-trees"><a href="#Advantages-of-LSM-trees" class="headerlink" title="Advantages of LSM-trees"></a>Advantages of LSM-trees</h5><p>LSM-trees are typically able to sustain higher write throughput than B- trees.</p>
<p>LSM-trees can be compressed better, and thus often produce smaller files on disk than B-trees. </p>
<h5 id="Downsides-of-LSM-trees"><a href="#Downsides-of-LSM-trees" class="headerlink" title="Downsides of LSM-trees"></a>Downsides of LSM-trees</h5><p>A downside of log-structured storage is that the compaction process can sometimes interfere with the performance of ongoing reads and writes. </p>
<p>Another issue with compaction arises at high write throughput: the disk’s finite write bandwidth needs to be shared between the initial write (logging and flushing a memtable to disk) and the compaction threads running in the background.</p>
<p>If write throughput is high and compaction is not configured carefully, it can happen that compaction cannot keep up with the rate of incoming writes.</p>
<p>An advantage of B-trees is that each key exists in exactly one place in the index, whereas a log-structured storage engine may have multiple copies of the same key in different segments. This aspect makes B-trees attractive in databases that want to offer strong transactional semantics: in many relational databases, transaction isola‐ tion is implemented using locks on ranges of keys, and in a B-tree index, those locks can be directly attached to the tree </p>
<h4 id="Other-Indexing-Structures"><a href="#Other-Indexing-Structures" class="headerlink" title="Other Indexing Structures"></a>Other Indexing Structures</h4><h5 id="Storing-values-within-the-index"><a href="#Storing-values-within-the-index" class="headerlink" title="Storing values within the index"></a>Storing values within the index</h5><p>In some situations, the extra hop from the index to the heap file is too much of a performance penalty for reads, so it can be desirable to store the indexed row directly within an index. This is known as a <em>clustered index</em>.</p>
<h5 id="Multi-column-indexes"><a href="#Multi-column-indexes" class="headerlink" title="Multi-column indexes"></a>Multi-column indexes</h5><p>…</p>
<h3 id="Transaction-Processing-or-Analytics"><a href="#Transaction-Processing-or-Analytics" class="headerlink" title="Transaction Processing or Analytics?"></a>Transaction Processing or Analytics?</h3><p>online transaction processing(OLTP)<br>online analytic processing (OLAP)</p>
<h4 id="Data-Warehousing"><a href="#Data-Warehousing" class="headerlink" title="Data Warehousing"></a>Data Warehousing</h4><p>The data warehouse con‐ tains a read-only copy of the data in all the various OLTP systems in the company. Data is extracted from OLTP databases (using either a periodic data dump or a con‐ tinuous stream of updates), transformed into an analysis-friendly schema, cleaned up, and then loaded into the data warehouse. This process of getting data into the warehouse is known as Extract–Transform–Load (ETL)</p>
<h5 id="The-divergence-between-OLTP-databases-and-data-warehouses"><a href="#The-divergence-between-OLTP-databases-and-data-warehouses" class="headerlink" title="The divergence between OLTP databases and data warehouses"></a>The divergence between OLTP databases and data warehouses</h5><h4 id="Stars-and-Snowflakes-Schemas-for-Analytics"><a href="#Stars-and-Snowflakes-Schemas-for-Analytics" class="headerlink" title="Stars and Snowflakes: Schemas for Analytics"></a>Stars and Snowflakes: Schemas for Analytics</h4><p>…</p>
<h3 id="Column-Oriented-Storage"><a href="#Column-Oriented-Storage" class="headerlink" title="Column-Oriented Storage"></a>Column-Oriented Storage</h3><p>…</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://rezelchen.github.io/2020/07/24/DDIA2/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="Ray Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ray Chen's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/2020/07/24/DDIA2/" class="post-title-link" itemprop="url">Note for DDIA in Chapter 2</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-07-24 18:54:40" itemprop="dateCreated datePublished" datetime="2020-07-24T18:54:40+00:00">2020-07-24</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-08-13 11:53:41" itemprop="dateModified" datetime="2020-08-13T11:53:41+00:00">2020-08-13</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h2 id="Data-Models-and-Query-Languages"><a href="#Data-Models-and-Query-Languages" class="headerlink" title="Data Models and Query Languages"></a>Data Models and Query Languages</h2><h3 id="Relational-Model-Versus-Document-Model"><a href="#Relational-Model-Versus-Document-Model" class="headerlink" title="Relational Model Versus Document Model"></a>Relational Model Versus Document Model</h3><h4 id="Many-to-One-and-Many-to-Many-Relationships"><a href="#Many-to-One-and-Many-to-Many-Relationships" class="headerlink" title="Many-to-One and Many-to-Many Relationships"></a>Many-to-One and Many-to-Many Relationships</h4><p>Removing such duplication is the key idea behind <em>normalization</em> in databases.</p>
<p>As a rule of thumb, if you’re duplicating values that could be stored in just one place, the schema is not normalized.</p>
<h4 id="Are-Document-Databases-Repeating-History"><a href="#Are-Document-Databases-Repeating-History" class="headerlink" title="Are Document Databases Repeating History?"></a>Are Document Databases Repeating History?</h4><h5 id="The-network-model"><a href="#The-network-model" class="headerlink" title="The network model"></a>The network model</h5><h5 id="The-relational-model"><a href="#The-relational-model" class="headerlink" title="The relational model"></a>The relational model</h5><h5 id="Comparison-to-document-databases"><a href="#Comparison-to-document-databases" class="headerlink" title="Comparison to document databases"></a>Comparison to document databases</h5><h4 id="Relational-Versus-Document-Databases-Today"><a href="#Relational-Versus-Document-Databases-Today" class="headerlink" title="Relational Versus Document Databases Today"></a>Relational Versus Document Databases Today</h4><h5 id="Which-data-model-leads-to-simpler-application-code"><a href="#Which-data-model-leads-to-simpler-application-code" class="headerlink" title="Which data model leads to simpler application code?"></a>Which data model leads to simpler application code?</h5><h5 id="Schema-flexibility-in-the-document-model"><a href="#Schema-flexibility-in-the-document-model" class="headerlink" title="Schema flexibility in the document model"></a>Schema flexibility in the document model</h5><p>A more accurate term is schema-on-read (the structure of the data is implicit, and only interpreted when the data is read), in contrast with schema-on-write (the traditional approach of relational databases, where the schema is explicit and the database ensures all written data conforms to it)</p>
<h5 id="Data-locality-for-queries"><a href="#Data-locality-for-queries" class="headerlink" title="Data locality for queries"></a>Data locality for queries</h5><h5 id="Convergence-of-document-and-relational-databases"><a href="#Convergence-of-document-and-relational-databases" class="headerlink" title="Convergence of document and relational databases"></a>Convergence of document and relational databases</h5><p>A hybrid of the relational and document models is a good route for databases to take in the future.</p>
<h3 id="Query-Languages-for-Data"><a href="#Query-Languages-for-Data" class="headerlink" title="Query Languages for Data"></a>Query Languages for Data</h3><p>A declarative query language is attractive because it is typically more concise and eas‐ ier to work with than an imperative API. But more importantly, it also hides imple‐ mentation details of the database engine, which makes it possible for the database system to introduce performance improvements without requiring any changes to queries.</p>
<h4 id="Declarative-Queries-on-the-Web"><a href="#Declarative-Queries-on-the-Web" class="headerlink" title="Declarative Queries on the Web"></a>Declarative Queries on the Web</h4><h4 id="MapReduce-Querying"><a href="#MapReduce-Querying" class="headerlink" title="MapReduce Querying"></a>MapReduce Querying</h4><p>MapReduce is a fairly low-level programming model for distributed execution on a cluster of machines. Higher-level query languages like SQL can be implemented as a pipeline of MapReduce operations but there are also many dis‐ tributed implementations of SQL that don’t use MapReduce.</p>
<p>Note there is nothing in SQL that constrains it to running on a single machine, and MapReduce doesn’t have a monopoly on distributed query execution.</p>
<h3 id="Graph-Like-Data-Models"><a href="#Graph-Like-Data-Models" class="headerlink" title="Graph-Like Data Models"></a>Graph-Like Data Models</h3><p>In the examples just given, all the vertices in a graph represent the same kind of thing (people, web pages, or road junctions, respectively). However, graphs are not limited to such homogeneous data: an equally powerful use of graphs is to provide a consis‐ tent way of storing completely different types of objects in a single datastore.</p>
<h4 id="Property-Graphs"><a href="#Property-Graphs" class="headerlink" title="Property Graphs"></a>Property Graphs</h4><p>properties of vertex:</p>
<ul>
<li>A unique identifier</li>
<li>A set of outgoing edges</li>
<li>A set of incoming edges</li>
<li>A collection of properties (key-value pairs)</li>
</ul>
<p>properties of edge:</p>
<ul>
<li>A unique identifier</li>
<li>The vertex at which the edge starts (the tail vertex)</li>
<li>The vertex at which the edge ends (the head vertex)</li>
<li>A label to describe the kind of relationship between the two vertices</li>
<li>A collection of properties (key-value pairs)</li>
</ul>
<p>You can think of a graph store as consisting of two relational tables, one for vertices and one for edges</p>
<h4 id="The-Cypher-Query-Language"><a href="#The-Cypher-Query-Language" class="headerlink" title="The Cypher Query Language"></a>The Cypher Query Language</h4><p>…</p>

      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  

      
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="en">
    <link itemprop="mainEntityOfPage" href="https://rezelchen.github.io/2020/05/27/DDIA1/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/blog/images/avatar.gif">
      <meta itemprop="name" content="Ray Chen">
      <meta itemprop="description" content="">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Ray Chen's Blog">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          
            <a href="/blog/2020/05/27/DDIA1/" class="post-title-link" itemprop="url">Note for DDIA in Chapter 1</a>
        </h2>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="far fa-calendar"></i>
              </span>
              <span class="post-meta-item-text">Posted on</span>

              <time title="Created: 2020-05-27 22:54:40" itemprop="dateCreated datePublished" datetime="2020-05-27T22:54:40+00:00">2020-05-27</time>
            </span>
              <span class="post-meta-item">
                <span class="post-meta-item-icon">
                  <i class="far fa-calendar-check"></i>
                </span>
                <span class="post-meta-item-text">Edited on</span>
                <time title="Modified: 2020-08-13 11:53:41" itemprop="dateModified" datetime="2020-08-13T11:53:41+00:00">2020-08-13</time>
              </span>

          

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
          <h3 id="Reliability"><a href="#Reliability" class="headerlink" title="Reliability"></a>Reliability</h3><ul>
<li>The application performs the function that the user expected.</li>
<li>It can tolerate the user making mistakes or using the software in unexpected ways.</li>
<li>Its performance is good enough for the required use case, under the expected load and data volume.</li>
<li>The system prevents any unauthorized access and abuse.</li>
</ul>
<h3 id="Scalability"><a href="#Scalability" class="headerlink" title="Scalability"></a>Scalability</h3><h4 id="Describing-Load"><a href="#Describing-Load" class="headerlink" title="Describing Load"></a>Describing Load</h4><p>Load can be described with a few numbers which we call <em>load parameters</em>. The best choice of parameters depends on the architecture of your system: it may be requests per second to a web server, the ratio of reads to writes in a database, the number of simultaneously active users in a chat room, the hit rate on a cache, or something else. Perhaps the average case is what matters for you, or perhaps your bottleneck is dominated by a small number of extreme cases.</p>
<h4 id="Describing-Performance"><a href="#Describing-Performance" class="headerlink" title="Describing Performance"></a>Describing Performance</h4><ul>
<li>throughput — the number of records we can process per second</li>
<li>the total time it takes to run a job on a dataset of a certain size</li>
<li>response time — the time between a client sending a request and receiving a response</li>
<li>latency is the duration that a request is waiting to be handled—during which it is <em>latent</em>, awaiting service</li>
</ul>
<p>High percentiles of response times, also known as <em>tail latencies</em>, are important because they directly affect users’ experience of the service.</p>
<h4 id="Approaches-for-Coping-with-Load"><a href="#Approaches-for-Coping-with-Load" class="headerlink" title="Approaches for Coping with Load"></a>Approaches for Coping with Load</h4><p>While distributing stateless services across multiple machines is fairly straightfor‐ ward, taking stateful data systems from a single node to a distributed setup can intro‐ duce a lot of additional complexity.</p>
<p>An architecture that scales well for a particular application is built around assumptions of which operations will be common and which will be rare — the load parameters.</p>
<p>Even though they are specific to a particular application, scalable architectures are nevertheless usually built from general-purpose building blocks, arranged in familiar patterns.</p>
<h3 id="Maintainability"><a href="#Maintainability" class="headerlink" title="Maintainability"></a>Maintainability</h3><h4 id="Operability-Making-Life-Easy-for-Operations"><a href="#Operability-Making-Life-Easy-for-Operations" class="headerlink" title="Operability: Making Life Easy for Operations"></a>Operability: Making Life Easy for Operations</h4><h4 id="Simplicity-Managing-Complexity"><a href="#Simplicity-Managing-Complexity" class="headerlink" title="Simplicity: Managing Complexity"></a>Simplicity: Managing Complexity</h4><h4 id="Evolvability-Making-Change-Easy"><a href="#Evolvability-Making-Change-Easy" class="headerlink" title="Evolvability: Making Change Easy"></a>Evolvability: Making Change Easy</h4>
      
    </div>

    
    
    
      <footer class="post-footer">
        <div class="post-eof"></div>
      </footer>
  </article>
  
  
  


  



        </div>
        

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 
  <span itemprop="copyrightYear">2020</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Ray Chen</span>
</div>
  <div class="powered-by">Powered by <a href="https://hexo.io" class="theme-link" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" class="theme-link" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

        








      </div>
    </footer>
  </div>

  
  <script src="/blog/lib/anime.min.js"></script>

<script src="/blog/js/utils.js"></script>

<script src="/blog/js/motion.js"></script>


<script src="/blog/js/schemes/muse.js"></script>


<script src="/blog/js/next-boot.js"></script>


  















  

  

</body>
</html>
